{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9606e0f3",
   "metadata": {},
   "source": [
    "# DeepSeek-V3.2 Chatbot\n",
    "\n",
    "This notebook runs a minimal chatbot against the Hugging Face hosted model `deepseek-ai/DeepSeek-V3.2`.\n",
    "\n",
    "Prereq: set an access token in your environment as `HF_TOKEN` (recommended) or set it in the cell below (not recommended for shared notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe6dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token setup\n",
    "import os\n",
    "\n",
    "# Recommended: set HF_TOKEN in your OS environment and restart the kernel.\n",
    "# Example (PowerShell): setx HF_TOKEN \"hf_...\"\n",
    "os.environ[\"HF_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "126669d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN set? True len= 37\n",
      "GET https://router.huggingface.co/hf-inference/models/deepseek-ai/DeepSeek-V3.2 -> 404\n",
      "Not Found\n"
     ]
    }
   ],
   "source": [
    "# Quick connectivity check (does NOT print your token)\n",
    "import os, requests\n",
    "\n",
    "hf = os.getenv(\"HF_TOKEN\")\n",
    "print(\"HF_TOKEN set?\", bool(hf), \"len=\", len(hf) if hf else None)\n",
    "\n",
    "# Router should exist (401/404/200 depends on auth/model availability)\n",
    "url = \"https://router.huggingface.co/hf-inference/models/deepseek-ai/DeepSeek-V3.2\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf}\"} if hf else {}\n",
    "r = requests.get(url, headers=headers, timeout=20)\n",
    "print(\"GET\", url, \"->\", r.status_code)\n",
    "print((r.text or \"\")[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c636726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST https://router.huggingface.co/v1/chat/completions -> 200\n",
      "{\"id\":\"58a044cf2762af690d388558c739250f\",\"object\":\"chat.completion\",\"created\":1767611248,\"model\":\"deepseek/deepseek-v3.2\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Hello, it's a pleasure to meet you.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":10,\"completion_tokens\":11,\"\n"
     ]
    }
   ],
   "source": [
    "# Test OpenAI-compatible router endpoint (optional)\n",
    "import os, requests, json\n",
    "\n",
    "hf = os.getenv(\"HF_TOKEN\")\n",
    "url = \"https://router.huggingface.co/v1/chat/completions\"\n",
    "payload = {\n",
    "    \"model\": \"deepseek-ai/DeepSeek-V3.2\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Say hello in one sentence.\"}],\n",
    "    \"max_tokens\": 32,\n",
    "    \"temperature\": 0.2,\n",
    "}\n",
    "headers = {\"Authorization\": f\"Bearer {hf}\", \"Content-Type\": \"application/json\"}\n",
    "resp = requests.post(url, headers=headers, json=payload, timeout=30)\n",
    "print(\"POST\", url, \"->\", resp.status_code)\n",
    "print((resp.text or \"\")[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "520e5693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready. Try: bot.reply('Hello!')\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import deepseek_chat\n",
    "\n",
    "importlib.reload(deepseek_chat)\n",
    "from deepseek_chat import DeepSeekChatbot\n",
    "\n",
    "bot = DeepSeekChatbot(model=\"deepseek-ai/DeepSeek-V3.2\")\n",
    "print(\"Ready. Try: bot.reply('Hello!')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d42c5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PDF attachment (RAG-lite) ---\n",
    "from __future__ import annotations\n",
    "\n",
    "import io\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Install lightweight deps if missing (safe to re-run)\n",
    "try:\n",
    "    from pypdf import PdfReader  # type: ignore\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pypdf\"])\n",
    "    from pypdf import PdfReader  # type: ignore\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets  # type: ignore\n",
    "    from IPython.display import display  # type: ignore\n",
    "except Exception:\n",
    "    widgets = None\n",
    "    display = None\n",
    "\n",
    "\n",
    "_WORD_RE = re.compile(r\"\\b\\w+\\b\", re.UNICODE)\n",
    "_STOPWORDS = {\n",
    "    \"the\",\"a\",\"an\",\"and\",\"or\",\"to\",\"of\",\"in\",\"on\",\"for\",\"with\",\"is\",\"are\",\"was\",\"were\",\"be\",\"as\",\"at\",\"by\",\"it\",\"this\",\"that\",\n",
    "    \"le\",\"la\",\"les\",\"un\",\"une\",\"des\",\"et\",\"ou\",\"de\",\"du\",\"dans\",\"sur\",\"pour\",\"avec\",\"est\",\"sont\",\"été\",\"être\",\"ce\",\"cet\",\"cette\",\"ces\",\n",
    "}\n",
    "\n",
    "\n",
    "def _tokenize(text: str) -> List[str]:\n",
    "    words = [w.lower() for w in _WORD_RE.findall(text)]\n",
    "    return [w for w in words if len(w) >= 2 and w not in _STOPWORDS]\n",
    "\n",
    "\n",
    "def _pdf_bytes_to_text(data: bytes) -> str:\n",
    "    reader = PdfReader(io.BytesIO(data))\n",
    "    parts: List[str] = []\n",
    "    for page in reader.pages:\n",
    "        try:\n",
    "            parts.append(page.extract_text() or \"\")\n",
    "        except Exception:\n",
    "            parts.append(\"\")\n",
    "    return \"\\n\".join(parts).strip()\n",
    "\n",
    "\n",
    "def load_pdf_from_path(path: str) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return _pdf_bytes_to_text(f.read())\n",
    "\n",
    "\n",
    "def chunk_text(text: str, *, max_chars: int = 1800, overlap: int = 250) -> List[str]:\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    chunks: List[str] = []\n",
    "    start = 0\n",
    "    n = len(text)\n",
    "    while start < n:\n",
    "        end = min(n, start + max_chars)\n",
    "        chunks.append(text[start:end])\n",
    "        if end >= n:\n",
    "            break\n",
    "        start = max(0, end - overlap)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def _score(query_tokens: List[str], chunk: str) -> int:\n",
    "    # Simple lexical overlap score (fast, no embeddings).\n",
    "    chunk_tokens = _tokenize(chunk)\n",
    "    if not chunk_tokens or not query_tokens:\n",
    "        return 0\n",
    "    chunk_set = set(chunk_tokens)\n",
    "    score = 0\n",
    "    for t in query_tokens:\n",
    "        if t in chunk_set:\n",
    "            score += 2\n",
    "    return score\n",
    "\n",
    "\n",
    "def retrieve_context(question: str, chunks: List[str], *, k: int = 4) -> List[Tuple[int, str]]:\n",
    "    q = _tokenize(question)\n",
    "    scored = [(i, _score(q, ch)) for i, ch in enumerate(chunks)]\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    top = [(i, chunks[i]) for i, s in scored[:k] if s > 0]\n",
    "    return top\n",
    "\n",
    "\n",
    "def build_context(excerpts: List[Tuple[int, str]]) -> str:\n",
    "    if not excerpts:\n",
    "        return \"\"\n",
    "    lines: List[str] = []\n",
    "    for i, ch in excerpts:\n",
    "        lines.append(f\"[Chunk {i+1}] {ch}\")\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AttachedPDF:\n",
    "    name: str\n",
    "    text: str\n",
    "    chunks: List[str]\n",
    "\n",
    "\n",
    "ATTACHED_PDF: AttachedPDF | None = None\n",
    "RETRIEVE_K = 4\n",
    "\n",
    "\n",
    "def attach_pdf_text(name: str, text: str) -> None:\n",
    "    global ATTACHED_PDF\n",
    "    chunks = chunk_text(text)\n",
    "    ATTACHED_PDF = AttachedPDF(name=name, text=text, chunks=chunks)\n",
    "    print(f\"Attached PDF: {name} ({len(text):,} chars, {len(chunks)} chunks)\")\n",
    "\n",
    "\n",
    "def clear_pdf() -> None:\n",
    "    global ATTACHED_PDF\n",
    "    ATTACHED_PDF = None\n",
    "    print(\"PDF cleared\")\n",
    "\n",
    "\n",
    "def ask_on_pdf(question: str, *, k: int | None = None) -> str:\n",
    "    if not ATTACHED_PDF:\n",
    "        return bot.reply(question)\n",
    "    k = RETRIEVE_K if k is None else k\n",
    "    excerpts = retrieve_context(question, ATTACHED_PDF.chunks, k=k)\n",
    "    context = build_context(excerpts)\n",
    "    prompt = (\n",
    "        \"You are evaluating a model. Answer the user's question using ONLY the provided document excerpts. \"\n",
    "        \"If the excerpts do not contain the answer, say you don't know and ask what to look for.\\n\\n\"\n",
    "        f\"Document: {ATTACHED_PDF.name}\\n\\n\"\n",
    "        f\"EXCERPTS:\\n{context if context else '[No relevant excerpts found]'}\\n\\n\"\n",
    "        f\"QUESTION:\\n{question}\"\n",
    "    )\n",
    "    return bot.reply(prompt)\n",
    "\n",
    "\n",
    "def _extract_first_upload(value) -> tuple[str, bytes] | None:\n",
    "    \"\"\"Return (filename, content_bytes) for the first uploaded file.\n",
    "\n",
    "    ipywidgets has changed FileUpload.value across versions: it can be a dict, tuple, or list.\n",
    "    \"\"\"\n",
    "    if not value:\n",
    "        return None\n",
    "    # Case 1: dict keyed by filename -> {\"file.pdf\": {\"content\": b\"...\", ...}}\n",
    "    if isinstance(value, dict):\n",
    "        first_key = next(iter(value.keys()))\n",
    "        first = value[first_key]\n",
    "        if isinstance(first, dict) and \"content\" in first:\n",
    "            name = first.get(\"name\") or first_key\n",
    "            return name, first[\"content\"]\n",
    "        # Sometimes it's already a dict with content\n",
    "        if isinstance(first, (bytes, bytearray)):\n",
    "            return first_key, bytes(first)\n",
    "    # Case 2: tuple/list of dicts -> ({\"name\":..., \"content\":...}, ...)\n",
    "    if isinstance(value, (tuple, list)):\n",
    "        first = value[0]\n",
    "        if isinstance(first, dict) and \"content\" in first:\n",
    "            name = first.get(\"name\") or \"uploaded.pdf\"\n",
    "            return name, first[\"content\"]\n",
    "        # Case 3: UploadedFile-like object\n",
    "        name = getattr(first, \"name\", \"uploaded.pdf\")\n",
    "        content = getattr(first, \"content\", None)\n",
    "        if content is None:\n",
    "            content = getattr(first, \"data\", None)\n",
    "        if content is None and isinstance(first, (bytes, bytearray)):\n",
    "            content = bytes(first)\n",
    "        if isinstance(content, (bytes, bytearray)):\n",
    "            return name, bytes(content)\n",
    "    # Fallback: try attributes on the value itself\n",
    "    name = getattr(value, \"name\", \"uploaded.pdf\")\n",
    "    content = getattr(value, \"content\", None)\n",
    "    if isinstance(content, (bytes, bytearray)):\n",
    "        return name, bytes(content)\n",
    "    return None\n",
    "\n",
    "\n",
    "def show_pdf_uploader() -> None:\n",
    "    if widgets is None or display is None:\n",
    "        print(\"ipywidgets not available in this environment. Use attach_pdf_text(load_pdf_from_path(...))\")\n",
    "        return\n",
    "    uploader = widgets.FileUpload(accept=\".pdf\", multiple=False)\n",
    "    button = widgets.Button(description=\"Load PDF\")\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def _on_click(_):\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            item = _extract_first_upload(uploader.value)\n",
    "            if not item:\n",
    "                print(\"Select a PDF first\")\n",
    "                return\n",
    "            name, data = item\n",
    "            text = _pdf_bytes_to_text(data)\n",
    "            attach_pdf_text(name, text)\n",
    "\n",
    "    button.on_click(_on_click)\n",
    "    display(widgets.VBox([widgets.HTML(\"<b>Attach a PDF</b>\"), uploader, button, out]))\n",
    "\n",
    "\n",
    "# Run this to attach a PDF via UI (if supported):\n",
    "# show_pdf_uploader()\n",
    "\n",
    "# Or attach from a local path (Windows example):\n",
    "# attach_pdf_text(\"my.pdf\", load_pdf_from_path(r\"C:\\\\path\\\\to\\\\file.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f794fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7ed9b486e64f70bc2291fbaa225031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Attach a PDF</b>'), FileUpload(value=(), accept='.pdf', description='Upload'), B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_pdf_uploader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98cb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    \"\"\"Interactive loop.\n",
    "\n",
    "    Commands:\n",
    "      /reset       clear chat history\n",
    "      /exit        quit\n",
    "      /pdf         show PDF status\n",
    "      /clearpdf    detach current PDF\n",
    "      /k N         set retrieval chunks (default 4)\n",
    "    \"\"\"\n",
    "    global RETRIEVE_K\n",
    "    print(\"Type '/reset', '/exit'. Use '/pdf' after attaching a PDF.\")\n",
    "    while True:\n",
    "        user = input(\"You> \").strip()\n",
    "        if not user:\n",
    "            continue\n",
    "        low = user.lower()\n",
    "        if low in {\"/exit\", \"/quit\"}:\n",
    "            break\n",
    "        if low == \"/reset\":\n",
    "            bot.reset()\n",
    "            print(\"(history cleared)\")\n",
    "            continue\n",
    "        if low == \"/pdf\":\n",
    "            if ATTACHED_PDF:\n",
    "                print(f\"(pdf attached: {ATTACHED_PDF.name}, {len(ATTACHED_PDF.chunks)} chunks, k={RETRIEVE_K})\")\n",
    "            else:\n",
    "                print(\"(no pdf attached) -> run show_pdf_uploader() or attach_pdf_text(...)\")\n",
    "            continue\n",
    "        if low == \"/clearpdf\":\n",
    "            clear_pdf()\n",
    "            continue\n",
    "        if low.startswith(\"/k \"):\n",
    "            try:\n",
    "                RETRIEVE_K = max(1, int(low.split()[1]))\n",
    "                print(f\"(k set to {RETRIEVE_K})\")\n",
    "            except Exception:\n",
    "                print(\"Usage: /k 4\")\n",
    "            continue\n",
    "\n",
    "        answer = ask_on_pdf(user) if ATTACHED_PDF else bot.reply(user)\n",
    "        print(f\"Bot> {answer}\\n\")\n",
    "\n",
    "\n",
    "# Run interactive chat in the notebook output\n",
    "# chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "146d9f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type '/reset', '/exit'. Use '/pdf' after attaching a PDF.\n",
      "(pdf attached: COLREG-Consolidated-2018.pdf, 66 chunks, k=4)\n",
      "Bot> According to the provided document excerpts, \"turning to port\" is indicated by **two short blasts** on the whistle.\n",
      "\n",
      "**Source:** Chunk 32 states: \"two short blasts to mean 'I am altering my course to port'\".\n",
      "\n",
      "Bot> Based solely on the provided excerpts, the signal for \"turning to port\" is **two short blasts** on the whistle.\n",
      "\n",
      "**Source:** Chunk 32 explicitly states: \"two short blasts to mean 'I am altering my course to port'\".\n",
      "\n",
      "Bot> Based solely on the provided excerpts, the signal for \"overtake on starboard\" is **two prolonged blasts followed by one short blast** on the whistle.\n",
      "\n",
      "**Source:** Chunk 33 states: \"two prolonged blasts followed by one short blast to mean 'I intend to overtake you on your starboard side'\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81c21283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: C:\\Users\\celli\\Documents\\.PIP2026\\PIP-2026-LOTUSim_G5_Fatigue\\Set évaluation RAG.csv\n",
      "PDF: C:\\Users\\celli\\Documents\\.PIP2026\\PIP-2026-LOTUSim_G5_Fatigue\\COLREG-Consolidated-2018.pdf\n",
      "Loaded 12 questions\n"
     ]
    }
   ],
   "source": [
    "# --- Batch evaluation from CSV (RAG) ---\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _find_existing_path(*candidates: str) -> Path:\n",
    "    for c in candidates:\n",
    "        p = Path(c)\n",
    "        if p.exists():\n",
    "            return p.resolve()\n",
    "    raise FileNotFoundError(f\"None of these paths exist: {candidates}\")\n",
    "\n",
    "\n",
    "def _read_csv_robust(path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except UnicodeDecodeError:\n",
    "        # Common fallbacks for Windows CSV exports\n",
    "        for enc in (\"utf-8-sig\", \"cp1252\", \"latin1\"):\n",
    "            try:\n",
    "                return pd.read_csv(path, encoding=enc)\n",
    "            except Exception:\n",
    "                pass\n",
    "        raise\n",
    "\n",
    "\n",
    "# Notebook usually runs with CWD = DeepSeek_test/. These files are at the workspace root.\n",
    "CSV_PATH = _find_existing_path(\n",
    "    \"Set évaluation RAG.csv\",\n",
    "    str(Path(\"..\") / \"Set évaluation RAG.csv\"),\n",
    "    str(Path(\"..\") / \"..\" / \"Set évaluation RAG.csv\"),\n",
    "    r\"C:\\Users\\celli\\Documents\\.PIP2026\\PIP-2026-LOTUSim_G5_Fatigue\\Set évaluation RAG.csv\",\n",
    ")\n",
    "PDF_PATH = _find_existing_path(\n",
    "    \"COLREG-Consolidated-2018.pdf\",\n",
    "    str(Path(\"..\") / \"COLREG-Consolidated-2018.pdf\"),\n",
    "    str(Path(\"..\") / \"..\" / \"COLREG-Consolidated-2018.pdf\"),\n",
    "    r\"C:\\Users\\celli\\Documents\\.PIP2026\\PIP-2026-LOTUSim_G5_Fatigue\\COLREG-Consolidated-2018.pdf\",\n",
    ")\n",
    "\n",
    "print(\"CSV:\", CSV_PATH)\n",
    "print(\"PDF:\", PDF_PATH)\n",
    "\n",
    "# Load CSV and keep only the Question column for now\n",
    "df_questions = _read_csv_robust(CSV_PATH)\n",
    "if \"Question\" not in df_questions.columns:\n",
    "    raise KeyError(f\"CSV must have a 'Question' column. Found: {list(df_questions.columns)}\")\n",
    "questions = df_questions[\"Question\"].dropna().astype(str).tolist()\n",
    "print(f\"Loaded {len(questions)} questions\")\n",
    "\n",
    "# Attach the PDF (only if not already attached or if you want to force reload)\n",
    "if ATTACHED_PDF is None or (ATTACHED_PDF.name != PDF_PATH.name):\n",
    "    attach_pdf_text(PDF_PATH.name, load_pdf_from_path(str(PDF_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84070ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10/12\n",
      "Done 12/12\n",
      "Saved: C:\\Users\\celli\\Documents\\.PIP2026\\PIP-2026-LOTUSim_G5_Fatigue\\DeepSeek_test\\rag_eval_answers.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation: ask each question on the attached PDF\n",
    "MAX_QUESTIONS = None  # set to an int for a quick dry-run, e.g. 5\n",
    "\n",
    "questions_to_run = questions if not MAX_QUESTIONS else questions[:MAX_QUESTIONS]\n",
    "results = []\n",
    "total = len(questions_to_run)\n",
    "for i, q in enumerate(questions_to_run, start=1):\n",
    "    bot.reset()  # avoid history leakage across questions\n",
    "    ans = ask_on_pdf(q)\n",
    "    results.append({\"Question\": q, \"Answer\": ans})\n",
    "    if i % 10 == 0 or i == total:\n",
    "        print(f\"Done {i}/{total}\")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.head()\n",
    "\n",
    "# Save results next to the notebook\n",
    "OUT_PATH = Path(\"rag_eval_answers.csv\").resolve()\n",
    "df_results.to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved:\", OUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
